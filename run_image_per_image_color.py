import cv2
import glob
import time
import yaml
import argparse
import numpy as np
import quaternion
from pathlib import Path

import pyicg

def inv_SE3(T):
    """
    Inverse of an SE(3) 4x4 array
    """
    Tinv = np.eye(4)
    Tinv[:3,:3] = T[:3,:3].T
    Tinv[:3,3] = -T[:3,:3].T@T[:3,3]
    return Tinv


def tq_to_SE3(t, q):
    """
    t: translation as list or array
    q: quaternion as list or array, expected order: xyzw
    out: 4x4 array representing the SE(3) transformation
    """
    T = np.eye(4)
    T[:3,3] = t
    # np.quaternion constructor uses wxyz order convention
    quat = np.quaternion(q[3], q[0], q[1], q[2]).normalized()
    T[:3,:3] = quaternion.as_rotation_matrix(quat)
    return T


def parse_script_input():
    parser = argparse.ArgumentParser(
        prog='run_image_per_image',
        description='Run the icg tracker image per image on '
    )

    parser.add_argument('-b', '--body_name',  dest='body_name',  type=str, required=True, help='Name of the object to track. need to match')
    parser.add_argument('-m', '--models_dir', dest='models_dir', type=str, required=True, help='Path to directory where object model file .obj is stored')
    parser.add_argument('-i', '--imgs_dir',   dest='imgs_dir',   type=str, required=True, help='Path to directory where "rbg*" and "depth*" named images are stored')
    parser.add_argument('--config_dir', dest='config_dir', type=str, default='config', help='Path to directory where <body_name>.yaml and static_detector.yaml files are stored')
    parser.add_argument('--tmp_dir',    dest='tmp_dir',    type=str, default='tmp', help='Directory to store preprocessing files generated by the tracker.')
    parser.add_argument('--detector_file', dest='detector_file', type=str, default='static_detector.yaml')
    parser.add_argument('--camera_file',   dest='camera_file',   type=str, default='cam_d435_640.yaml')
    parser.add_argument('--nb_img_load',   dest='nb_img_load',   type=int, default=-1)
    parser.add_argument('--use_depth',     dest='use_depth',     action='store_true', default=False)
    parser.add_argument('-s', '--stop',    dest='stop',          action='store_true', default=False)

    return parser.parse_args()


args = parse_script_input()

body_name = args.body_name
models_dir = Path(args.models_dir)
imgs_dir = Path(args.imgs_dir)
config_dir = Path(args.config_dir)
tmp_dir = Path(args.tmp_dir)
detector_file = args.detector_file
camera_file = args.camera_file
use_depth = args.use_depth
nb_img_load = args.nb_img_load
stop = args.stop


tracker = pyicg.Tracker('tracker', synchronize_cameras=False)

renderer_geometry = pyicg.RendererGeometry('renderer geometry')

with open(config_dir / camera_file, 'r') as f:
    cam = yaml.load(f.read(), Loader=yaml.UnsafeLoader)

color_camera = pyicg.DummyColorCamera('cam_color')
color_camera.color2depth_pose = tq_to_SE3(cam['trans_d_c'], cam['quat_d_c_xyzw'])
color_camera.intrinsics = pyicg.Intrinsics(**cam['intrinsics_color'])

# Viewers
color_viewer = pyicg.NormalColorViewer('color_viewer', color_camera, renderer_geometry)
# color_viewer.StartSavingImages('tmp', 'bmp')
color_viewer.set_opacity(0.5)  # [0.0-1.0]
tracker.AddViewer(color_viewer)

# Renderers (preprocessing)
color_depth_renderer = pyicg.FocusedBasicDepthRenderer('color_depth_renderer', renderer_geometry, color_camera)

# Bodies, careful about geometry units!
# - if error when generating sparse model view -> units too big
# - if object projection too smal -> units too big
geometry_unit_in_meter_ycbv_urdf = 0.001
metafile_path = models_dir / (body_name+'.yaml')
if metafile_path.exists():
    print('Body metafile_path constructor')
    body = pyicg.Body(body_name, metafile_path.as_posix())
else:
    print('Body full model path constructor')
    obj_files = list(models_dir.glob('*.obj'))
    if len(obj_files) >= 1:
        obj_path: Path = obj_files[0]
    else:
        raise FileNotFoundError('models_dir does not contain <body_name>.yaml or <body_name>.obj file')
    print('obj_path: ', obj_path)
    body = pyicg.Body(
        name=body_name,
        geometry_path=obj_path.as_posix(),
        geometry_unit_in_meter=geometry_unit_in_meter_ycbv_urdf,
        geometry_counterclockwise=1,
        geometry_enable_culling=1,
        geometry2body_pose=np.eye(4)
    )

renderer_geometry.AddBody(body)
color_depth_renderer.AddReferencedBody(body)

# Detector
detector_path = config_dir / detector_file
detector = pyicg.StaticDetector('static_detector', detector_path.as_posix(), body)
detector.SetUp()  # reads the definition
# tracker.AddDetector(detector)  # tracker sets up fine even without a detector!

# Models
region_model_path = tmp_dir / (body_name + '_region_model.bin')
region_model = pyicg.RegionModel(body_name + '_region_model', body, region_model_path.as_posix())

# Modalities
region_modality = pyicg.RegionModality(body_name + '_region_modality', body, color_camera, region_model)

optimizer = pyicg.Optimizer(body_name+'_optimizer')
optimizer.AddModality(region_modality)
tracker.AddOptimizer(optimizer)

# Do all the necessary heavy preprocessing
ok = tracker.SetUp()
if not ok:
    raise(ValueError('Error in SetUp'))

# read images from disk
rgb_names = sorted(glob.glob((imgs_dir / 'bgr*').as_posix()))

# LIMIT nb images
rgb_names = rgb_names[:nb_img_load]
print(f'{len(rgb_names)} images to load')

# load images from disk
color_read_flags = cv2.IMREAD_COLOR + cv2.IMREAD_ANYDEPTH
img_bgr_lst = [cv2.imread(name, color_read_flags) for name in rgb_names]  # loads a dtype=uint8 array

print(tracker.n_corr_iterations)
print(tracker.n_update_iterations)
# tracker.n_update_iterations = 2
tracker.n_update_iterations = 5

# Simulate one iteration of Tracker::RunTrackerProcess for loop
for it, img_bgr in enumerate(img_bgr_lst):
    print('Iter: ', it)
    # 1) Update camera image -> replaces a call to the camera UpdateImage method (which does nothing for Dummy(Color|Depth)Camera) 
    color_camera.image = img_bgr
    ok = tracker.UpdateCameras(True)  # poststep verifying the images have been properly setup
    if not ok:
        raise ValueError('Something is wrong with the provided images')

    if it == 0:
        # 2) Use detector or external init to update initial object pose
        # body.body2world_pose = detector.body2world_pose  # simulate external initial pose
        body.body2world_pose = detector.body2world_pose  # simulate external initial pose
        # tracker.ExecuteDetectionCycle(it)  # use detectector
        # tracker.DetectBodies()  # use detectector

        # 3) Initialise the different modalities (e.g. the color histograms)
        tracker.StartModalities(it)
        
    # 4) One tracking cycle (could call it several time)
    t = time.time()
    tracker.ExecuteTrackingCycle(it)
    print('ExecuteTrackingCycle (ms)', 1000*(time.time() - t))

    # 5) Render results
    t = time.time()
    tracker.UpdateViewers(it)
    print('UpdateViewers (ms)', 1000*(time.time() - t))

    if stop:
        cv2.waitKey(0)

