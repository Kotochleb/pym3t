"""
Example with full options:
python run_on_camera_sequence_realsense.py --use_region --use_depth --use_texture --measure_occlusions --use_depth_viewer -b obj_000014 -m <path/to/obj/dir>
"""

import numpy as np
import quaternion
import argparse
import pym3t
from pathlib import Path


def parse_script_input():
    parser = argparse.ArgumentParser(
        prog='run_on_camera_sequence_realsense',
        description='Run the m3t tracker image per image reading from realsense camera'
    )

    parser.add_argument('-b', '--body_name',  dest='body_name',  type=str, required=True, help='Name of the object to track. need to match')
    parser.add_argument('-m', '--models_dir', dest='models_dir', type=str, required=True, help='Path to directory where object model file {body_name}.obj is stored')
    parser.add_argument('--scale_geometry', dest='scale_geometry', default=0.001, type=float, required=False, help='Scale factor to convert model geometry to meters.')
    parser.add_argument('--tmp_dir',    dest='tmp_dir',    type=str, default='tmp', help='Directory to store preprocessing files generated by the tracker.')
    parser.add_argument('--use_region', dest='use_region', action='store_true', default=False)
    parser.add_argument('--use_depth', dest='use_depth', action='store_true', default=False)
    parser.add_argument('--use_texture', dest='use_texture', action='store_true', default=False)
    parser.add_argument('--use_depth_viewer', dest='use_depth_viewer', action='store_true', default=False)
    parser.add_argument('--model_occlusions', dest='model_occlusions', action='store_true', default=False)
    parser.add_argument('--measure_occlusions', dest='measure_occlusions', action='store_true', default=False)

    return parser.parse_args()


args = parse_script_input()
tmp_dir = Path(args.tmp_dir)
tmp_dir.mkdir(exist_ok=True)

# synchronize_cameras: to be able to print elapsed time
tracker = pym3t.Tracker('tracker', synchronize_cameras=False)
renderer_geometry = pym3t.RendererGeometry('renderer geometry')
color_camera = pym3t.RealSenseColorCamera('realsense_color')
if args.use_depth:
    depth_camera = pym3t.RealSenseDepthCamera('realsense_depth')

# Most time is spent on rendering (tested without GPU: ~15 ms for both, 8 for color only)
color_viewer = pym3t.NormalColorViewer('color_viewer', color_camera, renderer_geometry)
tracker.AddViewer(color_viewer)
if args.use_depth and args.use_depth_viewer:
    depth_viewer = pym3t.NormalDepthViewer('depth_viewer_name', depth_camera, renderer_geometry)
    tracker.AddViewer(depth_viewer)

# Setup body model and properties
obj_model_path = Path(args.models_dir) / f'{args.body_name}.obj'
print(f'Loading object {obj_model_path}')
body = pym3t.Body(
    name=args.body_name,
    geometry_path=obj_model_path.as_posix(),
    geometry_unit_in_meter=args.scale_geometry,
    geometry_counterclockwise=1,
    geometry_enable_culling=1,
    geometry2body_pose=np.eye(4)
)
renderer_geometry.AddBody(body)

# Set up link (m3t handles polyarticulated systems, here we have only one link corresponding to the object)
link = pym3t.Link(args.body_name + '_link', body)

# Shared renderer between region and texture 
if args.model_occlusions and (args.use_region or args.use_texture):
    focused_color_depth_renderer = pym3t.FocusedBasicDepthRenderer('focused_color_depth_renderer', renderer_geometry, color_camera)
    focused_color_depth_renderer.AddReferencedBody(body)

# Region Modality
if args.use_region:
    region_model_path = tmp_dir / (args.body_name + '_region_model.bin')
    region_model = pym3t.RegionModel(args.body_name + '_region_model', body, region_model_path.as_posix())
    region_modality = pym3t.RegionModality(args.body_name + '_region_modality', body, color_camera, region_model)
    if args.model_occlusions:
        region_modality.ModelOcclusions(focused_color_depth_renderer)
    if args.measure_occlusions and args.use_depth:
        region_modality.MeasureOcclusions(depth_camera)
    link.AddModality(region_modality)

# Depth Modality
if args.use_depth:
    depth_model_path = tmp_dir / (args.body_name + '_depth_model.bin')
    depth_model = pym3t.DepthModel(args.body_name + '_depth_model', body, depth_model_path.as_posix())
    depth_modality = pym3t.DepthModality(args.body_name + '_depth_modality', body, depth_camera, depth_model)
    if args.model_occlusions:
        focused_depth_depth_renderer = pym3t.FocusedBasicDepthRenderer('focused_depth_depth_renderer', renderer_geometry, depth_camera)
        focused_depth_depth_renderer.AddReferencedBody(body)
        depth_modality.ModelOcclusions(focused_depth_depth_renderer)
    if args.measure_occlusions and args.use_depth:
        depth_modality.MeasureOcclusions()
    link.AddModality(depth_modality)

# Texture Modality
if args.use_texture:
    # Texture modality does not require a model contrary to region and depth (for sparse view precomputations)
    color_silhouette_renderer = pym3t.FocusedSilhouetteRenderer('color_silhouette_renderer', renderer_geometry, color_camera)
    color_silhouette_renderer.AddReferencedBody(body)
    texture_modality = pym3t.TextureModality(args.body_name + '_texture_modality', body, color_camera, color_silhouette_renderer)
    if args.model_occlusions:
        texture_modality.ModelOcclusions(focused_color_depth_renderer)
    if args.measure_occlusions and args.use_depth:
        texture_modality.MeasureOcclusions(depth_camera)
    link.AddModality(texture_modality)


optimizer = pym3t.Optimizer(args.body_name+'_optimizer', link)
tracker.AddOptimizer(optimizer)

#----------------
# Intialize object pose
link2world_pose = np.array([ 1, 0,  0, 0,
                             0, 0, -1, 0,
                             0, 1,  0, 0.556,
                             0, 0,  0, 1 ]).reshape((4,4))
dR_l = quaternion.as_rotation_matrix(quaternion.from_rotation_vector([0.2,0,0.0]))
link2world_pose[:3,:3] = link2world_pose[:3,:3] @ dR_l
#----------------

detector = pym3t.StaticDetector('static_detector', optimizer, link2world_pose, False)
tracker.AddDetector(detector)

ok = tracker.SetUp()
print('tracker.SetUp ok: ', ok)
names_detecting = {args.body_name}
names_starting = {args.body_name}
tracker.RunTrackerProcess(execute_detection=True, start_tracking=True, names_detecting=names_detecting, names_starting=names_starting)
